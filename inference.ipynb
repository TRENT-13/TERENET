{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e15aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# Cell 2: Define TereNet Architecture\n",
    "class TereNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(TereNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(512)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.dropout(F.relu(self.bn_fc1(self.fc1(x))))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Cell 3: Define the infer function\n",
    "def infer(data_dir, model_path):\n",
    "    \"\"\"\n",
    "    Load trained model and predict classes for all images in data_dir.\n",
    "    Saves results to results.json.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing images to classify\n",
    "        model_path: Path to saved model (.pth file)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping filenames to predicted class names\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    # Determine number of classes from the last layer\n",
    "    if isinstance(checkpoint, torch.nn.Module):\n",
    "        model = checkpoint\n",
    "        print(\"Loaded complete model\")\n",
    "        num_classes = model.fc2.out_features\n",
    "    else:\n",
    "        print(\"Loaded state_dict, reconstructing model...\")\n",
    "        \n",
    "        # Get number of classes from fc2 layer\n",
    "        if 'fc2.weight' in checkpoint:\n",
    "            num_classes = checkpoint['fc2.weight'].shape[0]\n",
    "        else:\n",
    "            raise ValueError(\"Could not determine number of classes from checkpoint\")\n",
    "        \n",
    "        print(f\"Detected {num_classes} classes from model\")\n",
    "        \n",
    "        # Create model with detected number of classes\n",
    "        model = TereNet(num_classes=num_classes)\n",
    "        model.load_state_dict(checkpoint)\n",
    "        print(\"Successfully loaded model weights!\")\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Same transform as used during training/validation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load class names\n",
    "    class_names = None\n",
    "    \n",
    "    # Try to find class names from q.json\n",
    "    if os.path.exists('q.json'):\n",
    "        with open('q.json', 'r') as f:\n",
    "            class_names = json.load(f)\n",
    "        print(f\"Loaded {len(class_names)} classes from q.json\")\n",
    "    \n",
    "    # Try to find from data directory\n",
    "    elif os.path.exists('data_dir'):\n",
    "        data_path = Path('data')\n",
    "        class_dirs = sorted([d.name for d in data_path.iterdir() if d.is_dir()])\n",
    "        if class_dirs:\n",
    "            class_names = class_dirs\n",
    "            print(f\"Inferred {len(class_names)} classes from data directory\")\n",
    "            print(f\"Classes: {class_names[:5]}...\" if len(class_names) > 5 else f\"Classes: {class_names}\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Get all images from data_dir\n",
    "    data_path = Path(data_dir)\n",
    "    if not data_path.exists():\n",
    "        raise ValueError(f\"Directory {data_dir} does not exist\")\n",
    "    \n",
    "    image_files = [f for f in data_path.iterdir() \n",
    "                   if f.suffix.lower() in {'.jpg', '.jpeg', '.png', '.bmp','.webp'}]\n",
    "    print(f\"Found {len(image_files)} images to process\")\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(f\"Warning: No images found in {data_dir}\")\n",
    "        return {}\n",
    "    \n",
    "    # Predict\n",
    "    predictions = {}\n",
    "    with torch.no_grad():\n",
    "        for i, img_path in enumerate(image_files, 1):\n",
    "            try:\n",
    "                # Load and transform image\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "                \n",
    "                # Make prediction\n",
    "                output = model(image_tensor)\n",
    "                _, predicted_idx = torch.max(output, 1)\n",
    "                predicted_class = class_names[predicted_idx.item()]\n",
    "                \n",
    "                predictions[img_path.name] = predicted_class\n",
    "                \n",
    "                if i % 10 == 0 or i == len(image_files):\n",
    "                    print(f\"Processed {i}/{len(image_files)} images\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path.name}: {e}\")\n",
    "                predictions[img_path.name] = \"error\"\n",
    "    \n",
    "    # Save results\n",
    "    with open('results.json', 'w') as f:\n",
    "        json.dump(predictions, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nPredictions saved to results.json\")\n",
    "    return predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab6b6191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loaded state_dict, reconstructing model...\n",
      "Detected 42 classes from model\n",
      "Successfully loaded model weights!\n",
      "Loaded 42 classes from q.json\n",
      "Found 2 images to process\n",
      "Processed 2/2 images\n",
      "\n",
      "Predictions saved to results.json\n",
      "\n",
      "============================================================\n",
      "INFERENCE COMPLETE: Predicted 2 images\n",
      "============================================================\n",
      "\n",
      "Prediction Results:\n",
      "============================================================\n",
      "  ðŸ“· bart.png             â†’ Data\\Archive\\Characters Train\\Bart Simpson\n",
      "  ðŸ“· marge_simpson.jpg    â†’ Data\\Archive\\Characters Train\\Marge Simpson\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "data_directory = 'data_dir'\n",
    "model_file = 'terenet_model1.pth'\n",
    "\n",
    "\n",
    "\n",
    "# Run inference\n",
    "if Path(data_directory).exists() and Path(model_file).exists():\n",
    "    results = infer(data_directory, model_file)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"INFERENCE COMPLETE: Predicted {len(results)} images\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Display all predictions with more detail\n",
    "    print(\"\\nPrediction Results:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for filename, pred_class in results.items():\n",
    "        # Clean up the class name for display\n",
    "        display_name = pred_class.replace('_', ' ').title()\n",
    "        print(f\"  ðŸ“· {filename:20s} â†’ {display_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6042f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d01dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart.png -> data\\archive\\characters_train\\bart_simpson\n",
      "marge_simpson.jpg -> data\\archive\\characters_train\\marge_simpson\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21e083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4932352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
